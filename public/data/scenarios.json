{
  "project": "LLM-Explorer",
  "version": "4.00",
  "scenarios": [
    {
      "id": "polysemie-schloss-labor",
      "name": "Mehrdeutigkeit: Das Schloss (Kausalit√§ts-Modus)",
      "input_prompt": "Das Schloss war f√ºr den Einbrecher kein Hindernis.",
      "explanation": "Visualisierung der vertikalen Kausalit√§t: Der Kontext 'Einbrecher' (Phase 2) aktiviert die mechanische Kategorie (Phase 3), was in Phase 4 den Token 'T√ºrschloss' gegen√ºber 'Prachtbau' gewinnen l√§sst.",
      "phase_0_tokenization": {
        "tokens": [
          {
            "id": "0",
            "text": "Das"
          },
          {
            "id": "1",
            "text": "Schloss"
          },
          {
            "id": "2",
            "text": "war"
          },
          {
            "id": "3",
            "text": "f√ºr"
          },
          {
            "id": "4",
            "text": "den"
          },
          {
            "id": "5",
            "text": "Einbrecher"
          },
          {
            "id": "6",
            "text": "kein"
          },
          {
            "id": "7",
            "text": "Hindernis"
          }
        ]
      },
      "phase_1_embedding": {
        "token_vectors": [
          {
            "token_index": 0,
            "base_vector": [
              0.1,
              0.1
            ],
            "positional_vector": [
              -0.5,
              0.0
            ]
          },
          {
            "token_index": 1,
            "base_vector": [
              0.5,
              0.5
            ],
            "positional_vector": [
              -0.3,
              0.0
            ]
          },
          {
            "token_index": 5,
            "base_vector": [
              0.8,
              0.7
            ],
            "positional_vector": [
              0.3,
              0.0
            ]
          },
          {
            "token_index": 7,
            "base_vector": [
              0.1,
              0.1
            ],
            "positional_vector": [
              0.6,
              0.0
            ]
          }
        ]
      },
      "phase_2_attention": {
        "attention_profiles": [
          {
            "id": "context-check",
            "label": "Kontext-Analyse",
            "rules": [
              {
                "head": 1,
                "label": "Semantik",
                "source": "1",
                "target": "7",
                "strength": 1.2
              },
              {
                "head": 3,
                "label": "Logik/Mechanik",
                "source": "1",
                "target": "5",
                "strength": 1.4
              }
            ]
          }
        ]
      },
      "phase_3_ffn": {
        "activations": [
          {
            "id": "funktional",
            "label": "Mechanik/Sicherheit",
            "activation_default": 0.8,
            "linked_head": 3,
            "color": "#10b981",
            "icon": "‚öôÔ∏è",
            "suggested_token": "T√ºrschloss"
          },
          {
            "id": "akademisch",
            "label": "Architektur/Pracht",
            "activation_default": 0.2,
            "linked_head": 1,
            "color": "#3b82f6",
            "icon": "üèõÔ∏è",
            "suggested_token": "Prachtbau"
          },
          {
            "id": "neutral",
            "label": "Grammatik",
            "activation_default": 1.0,
            "is_hidden": true,
            "suggested_token": "Das"
          }
        ]
      },
      "phase_4_decoding": {
        "settings": {
          "sampling_mode": "top_k",
          "default_temperature": 0.7,
          "logit_bias_multiplier": 12,
          "entropy_visual_threshold": 0.3
        },
        "top_k_tokens": [
          {
            "token": "T√ºrschloss",
            "base_logit": 4.2,
            "category_link": "funktional",
            "noise_sensitivity": 0.5
          },
          {
            "token": "Prachtbau",
            "base_logit": 4.2,
            "category_link": "akademisch",
            "noise_sensitivity": 0.5
          },
          {
            "token": "Das",
            "base_logit": 3.8,
            "category_link": "neutral",
            "noise_sensitivity": 0.1
          },
          {
            "token": "Residenz",
            "base_logit": 3.5,
            "category_link": "akademisch",
            "noise_sensitivity": 0.6
          },
          {
            "token": "Riegel",
            "base_logit": 3.2,
            "category_link": "funktional",
            "noise_sensitivity": 0.7
          }
        ]
      }
    },
    {
      "id": "halluzinations-labor-01",
      "name": "Halluzinations-Labor: Logik am Limit",
      "input_prompt": "Die Hauptstadt von Frankreich ist...",
      "explanation": "Dieses Szenario demonstriert, wie niedrige Wissens-Aktivierung (Phase 3) bei hohem Rauschen (Phase 4) zu Halluzinationen f√ºhrt. Schiebe den Noise-Regler hoch, um zu sehen, wie 'Paris' seine Dominanz verliert.",
      "phase_0_tokenization": {
        "tokens": [
          {
            "id": "0",
            "text": "Die"
          },
          {
            "id": "1",
            "text": "Hauptstadt"
          },
          {
            "id": "2",
            "text": "von"
          },
          {
            "id": "3",
            "text": "Frankreich"
          },
          {
            "id": "4",
            "text": "ist"
          }
        ]
      },
      "phase_1_embedding": {
        "token_vectors": [
          {
            "token_index": 1,
            "base_vector": [
              0.8,
              0.2
            ],
            "positional_vector": [
              -0.4,
              0.1
            ]
          },
          {
            "token_index": 3,
            "base_vector": [
              0.2,
              0.8
            ],
            "positional_vector": [
              0.3,
              0.1
            ]
          }
        ]
      },
      "phase_2_attention": {
        "attention_profiles": [
          {
            "id": "fact-retrieval",
            "label": "Fakten-Abruf",
            "rules": [
              {
                "head": 3,
                "label": "Geografie-Logik",
                "source": "3",
                "target": "1",
                "strength": 1.5
              },
              {
                "head": 1,
                "label": "Rauschen/Chaos",
                "source": "4",
                "target": "0",
                "strength": 0.2
              }
            ]
          }
        ]
      },
      "phase_3_ffn": {
        "activations": [
          {
            "id": "geografie",
            "label": "Geografisches Wissen",
            "activation_default": 0.9,
            "linked_head": 3,
            "color": "#10b981",
            "icon": "üåç",
            "suggested_token": "Paris"
          },
          {
            "id": "instabil",
            "label": "Zuf√§llige Assoziationen",
            "activation_default": 0.1,
            "linked_head": 1,
            "color": "#f59e0b",
            "icon": "üåÄ",
            "suggested_token": "Bananenrepublik"
          }
        ]
      },
      "phase_4_decoding": {
        "settings": {
          "sampling_mode": "top_k",
          "default_temperature": 1.2,
          "logit_bias_multiplier": 14,
          "entropy_visual_threshold": 0.4
        },
        "top_k_tokens": [
          {
            "token": "Paris",
            "base_logit": 5.0,
            "category_link": "geografie",
            "noise_sensitivity": 0.2,
            "hallucination_risk": 0.1
          },
          {
            "token": "Bananenrepublik",
            "base_logit": 3.8,
            "category_link": "instabil",
            "noise_sensitivity": 0.9,
            "hallucination_risk": 0.95
          },
          {
            "token": "London",
            "base_logit": 4.5,
            "category_link": "geografie",
            "noise_sensitivity": 0.4,
            "hallucination_risk": 0.3
          },
          {
            "token": "Baguette",
            "base_logit": 3.5,
            "category_link": "instabil",
            "noise_sensitivity": 0.8,
            "hallucination_risk": 0.8
          }
        ]
      }
    },
    {
      "id": "gender-bias-chirurgie-01",
      "name": "Gender-Bias: Das Skalpell",
      "input_prompt": "Die Person f√ºhrt das Skalpell. Es handelt sich um eine...",
      "explanation": "Dieses Szenario zeigt, wie ein trainierter Bias (Head 1) die neutrale Kategorie 'Medizin' in Phase 3 maskulin einf√§rbt. In Phase 4 gewinnt 'Arzt' gegen√ºber '√Ñrztin', obwohl der Text geschlechtsneutral ist.",
      "phase_0_tokenization": {
        "tokens": [
          {
            "id": "0",
            "text": "Die"
          },
          {
            "id": "1",
            "text": "Person"
          },
          {
            "id": "2",
            "text": "f√ºhrt"
          },
          {
            "id": "3",
            "text": "das"
          },
          {
            "id": "4",
            "text": "Skalpell"
          },
          {
            "id": "5",
            "text": "."
          }
        ]
      },
      "phase_1_embedding": {
        "token_vectors": [
          {
            "token_index": 1,
            "base_vector": [
              0.4,
              0.4
            ],
            "positional_vector": [
              0.0,
              0.0
            ]
          },
          {
            "token_index": 4,
            "base_vector": [
              0.6,
              0.7
            ],
            "positional_vector": [
              0.2,
              0.1
            ]
          }
        ]
      },
      "phase_2_attention": {
        "attention_profiles": [
          {
            "id": "stereotypes",
            "label": "Soziale Muster (Stereotype)",
            "rules": [
              {
                "head": 1,
                "label": "Maskuliner Bias",
                "source": "4",
                "target": "1",
                "strength": 1.4
              },
              {
                "head": 3,
                "label": "Berufs-Logik",
                "source": "4",
                "target": "1",
                "strength": 0.9
              }
            ]
          }
        ]
      },
      "phase_3_ffn": {
        "activations": [
          {
            "id": "maskulin",
            "label": "Kategorie: Maskulin",
            "activation_default": 0.8,
            "linked_head": 1,
            "color": "#3b82f6",
            "icon": "üë®",
            "suggested_token": "Arzt"
          },
          {
            "id": "feminin",
            "label": "Kategorie: Feminin",
            "activation_default": 0.2,
            "linked_head": 4,
            "color": "#ec4899",
            "icon": "üë©",
            "suggested_token": "√Ñrztin"
          },
          {
            "id": "medizin",
            "label": "Kategorie: Medizin",
            "activation_default": 0.9,
            "linked_head": 3,
            "color": "#10b981",
            "icon": "üè•",
            "suggested_token": "Chirurg"
          }
        ]
      },
      "phase_4_decoding": {
        "settings": {
          "sampling_mode": "top_k",
          "default_temperature": 0.7,
          "logit_bias_multiplier": 12,
          "entropy_visual_threshold": 0.3
        },
        "top_k_tokens": [
          {
            "token": "Arzt",
            "base_logit": 4.8,
            "category_link": "maskulin",
            "noise_sensitivity": 0.3
          },
          {
            "token": "√Ñrztin",
            "base_logit": 4.8,
            "category_link": "feminin",
            "noise_sensitivity": 0.3
          },
          {
            "token": "Chirurg",
            "base_logit": 3.5,
            "category_link": "maskulin",
            "noise_sensitivity": 0.4
          }
        ]
      }
    },
    {
      "id": "hauptstadt-multi-kontext-01",
      "name": "Hauptstadt: Der Kontext-Mixer",
      "input_prompt": "Die Hauptstadt von Deutschland ist...",
      "explanation": "Dieses Szenario demonstriert Multi-Head-Inferenz. Jeder Head repr√§sentiert einen anderen Fokus: Fakten (Berlin), Geschichte (Bonn), √Ñsthetik (sch√∂n), Umgebung (laut) oder Distanz (weit weg).",
      "phase_0_tokenization": {
        "tokens": [
          {
            "id": "0",
            "text": "Die"
          },
          {
            "id": "1",
            "text": "Hauptstadt"
          },
          {
            "id": "2",
            "text": "von"
          },
          {
            "id": "3",
            "text": "Deutschland"
          },
          {
            "id": "4",
            "text": "ist"
          }
        ]
      },
      "phase_1_embedding": {
        "token_vectors": [
          {
            "token_index": 1,
            "base_vector": [
              0.8,
              0.1
            ],
            "positional_vector": [
              0.1,
              0.0
            ]
          },
          {
            "token_index": 3,
            "base_vector": [
              0.2,
              0.9
            ],
            "positional_vector": [
              0.3,
              0.1
            ]
          },
          {
            "token_index": 4,
            "base_vector": [
              0.5,
              0.5
            ],
            "positional_vector": [
              0.5,
              0.2
            ]
          }
        ]
      },
      "phase_2_attention": {
        "attention_profiles": [
          {
            "id": "mindset-selector",
            "label": "KI-Aufmerksamkeits-Fokus",
            "rules": [
              {
                "head": 3,
                "label": "Fakten-Abruf",
                "source": "3",
                "target": "1",
                "strength": 1.4
              },
              {
                "head": 4,
                "label": "Historisches Wissen",
                "source": "3",
                "target": "0",
                "strength": 1.1
              },
              {
                "head": 2,
                "label": "√Ñsthetik/Gef√ºhl",
                "source": "4",
                "target": "1",
                "strength": 1.2
              },
              {
                "head": 1,
                "label": "Sensorik/Umgebung",
                "source": "4",
                "target": "2",
                "strength": 1.1
              }
            ]
          }
        ]
      },
      "phase_3_ffn": {
        "activations": [
          {
            "id": "geografie",
            "label": "Fakten-Speicher",
            "linked_head": 3,
            "color": "#10b981",
            "icon": "üìö"
          },
          {
            "id": "geschichte",
            "label": "Archiv-Wissen",
            "linked_head": 4,
            "color": "#8b5cf6",
            "icon": "‚è≥"
          },
          {
            "id": "emotion",
            "label": "Affektive Ebene",
            "linked_head": 2,
            "color": "#ec4899",
            "icon": "üíñ"
          },
          {
            "id": "sensorik",
            "label": "Umgebung/L√§rm",
            "linked_head": 1,
            "color": "#f59e0b",
            "icon": "üöó"
          }
        ]
      },
      "phase_4_decoding": {
        "settings": {
          "default_temperature": 0.7,
          "default_noise": 0.0,
          "default_mlp_threshold": 0.3,
          "logit_bias_multiplier": 16
        },
        "top_k_tokens": [
          {
            "token": "Berlin",
            "base_logit": 5.2,
            "category_link": "geografie"
          },
          {
            "token": "Bonn",
            "base_logit": 4.0,
            "category_link": "geschichte"
          },
          {
            "token": "sch√∂n",
            "base_logit": 4.5,
            "category_link": "emotion"
          },
          {
            "token": "laut",
            "base_logit": 4.3,
            "category_link": "sensorik"
          },
          {
            "token": "weit weg",
            "base_logit": 3.5,
            "category_link": "sensorik"
          }
        ]
      }
    }
  ]
}