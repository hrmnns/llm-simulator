{
  "project": "LLM-Explorer",
  "version": "4.01",
  "scenarios": [
    {
      "id": "hauptstadt-multi-kontext-v02",
      "name": "Hauptstadt: Der Kontext-Mixer",
      "input_prompt": "Die Hauptstadt von Deutschland ist...",
      "explanation": "Dieses Szenario demonstriert, wie ein Transformer-Modell zwischen faktischem Wissen, historischem Archiv-Wissen und subjektiven Bewertungen (Emotion/Sensorik) wechselt, je nachdem, welcher Attention-Pfad durch den Nutzer oder den Kontext verst√§rkt wird.",
      "phase_0_tokenization": {
        "tokens": [
          {
            "id": "0",
            "text": "Die",
            "explanation": "Bestimmter Artikel, Feminin. In diesem Kontext fungiert er als struktureller Anker. Linguistisch leitet er das Subjekt ein und dient im Modell oft als Tr√§ger f√ºr den √ºbergeordneten Satz-Modus (z.B. historisch vs. aktuell)."
          },
          {
            "id": "1",
            "text": "Hauptstadt",
            "explanation": "Ein relationales Nomen, das zwingend eine Erg√§nzung (von X) erfordert. Es aktiviert im FFN-Layer komplexe Wissensstrukturen √ºber Geografie, Verwaltung und nationale Identit√§t."
          },
          {
            "id": "2",
            "text": "von",
            "explanation": "Pr√§position zur Einleitung des Genitiv-Attributs. Sie stellt die logische Verbindung zwischen dem Konzept 'Hauptstadt' und der spezifischen Entit√§t 'Deutschland' her."
          },
          {
            "id": "3",
            "text": "Deutschland",
            "explanation": "Eigennamen-Entit√§t. Dies ist der prim√§re Fakten-Anker im Vektorraum. Er liefert die notwendigen Koordinaten, um aus der allgemeinen Kategorie 'Hauptstadt' einen spezifischen geografischen Punkt zu extrahieren."
          },
          {
            "id": "4",
            "text": "ist",
            "explanation": "Kopula-Verb (Sein). Es dient als Pr√§dikat und stellt die √Ñquivalenz zwischen dem Subjekt und dem kommenden Pr√§dikatsnomen her. Im Decoding-Prozess ist dies der Moment der h√∂chsten Entropie vor der Entscheidung."
          }
        ]
      },
      "phase_1_embedding": {
        "axis_map": {
          "x_axis": {
            "positive": "Fakten & Entit√§ten",
            "negative": "Syntax & Funktion",
            "description": "Die X-Achse trennt inhaltliche Ankerpunkte (Berlin, Deutschland) von rein funktionalen Sprachelementen (ist, von)."
          },
          "y_axis": {
            "positive": "Kontext-Abh√§ngigkeit",
            "negative": "Semantische Dichte",
            "description": "Die Y-Achse zeigt, ob ein Token aktiv nach Informationen in der Umgebung sucht oder selbst eine abgeschlossene Bedeutung tr√§gt."
          }
        },
        "token_vectors": [
          {
            "token_index": 0,
            "text": "Die",
            "base_vector": [
              -0.9,
              0.8
            ],
            "positional_vector": [
              -0.1,
              0.1
            ],
            "explanation": "Struktureller Artikel: Dient hier als prim√§re Quelle f√ºr den historischen Pfad (Head 4), um Zust√§nde wie 'ehemalig' zu adressieren."
          },
          {
            "token_index": 1,
            "text": "Hauptstadt",
            "base_vector": [
              0.2,
              0.6
            ],
            "positional_vector": [
              0.1,
              -0.1
            ],
            "explanation": "Relationales Nomen: Besetzt eine zentrale Position im Vektorraum und wartet auf die Spezifizierung durch die 'Deutschland'-Entit√§t."
          },
          {
            "token_index": 2,
            "text": "von",
            "base_vector": [
              -0.7,
              0.9
            ],
            "positional_vector": [
              -0.2,
              0.2
            ],
            "explanation": "Connector: Erzeugt ein starkes Signal f√ºr geografische Relationen und Distanzberechnungen (Head 1)."
          },
          {
            "token_index": 3,
            "text": "Deutschland",
            "base_vector": [
              0.95,
              -0.8
            ],
            "positional_vector": [
              0.3,
              -0.2
            ],
            "explanation": "Massive Entit√§t: Liefert die h√∂chste semantische Dichte und fungiert als Zielpunkt f√ºr fast alle Attention-Heads."
          },
          {
            "token_index": 4,
            "text": "ist",
            "base_vector": [
              -0.85,
              0.7
            ],
            "positional_vector": [
              -0.15,
              0.3
            ],
            "explanation": "Verb-Knoten: Erzeugt die Spannung f√ºr das nachfolgende Token und steuert via Head 1 sensorische Assoziationen (laut/sch√∂n)."
          }
        ]
      },
      "phase_2_attention": {
        "attention_profiles": [
          {
            "id": "mindset-selector",
            "label": "KI-Aufmerksamkeits-Fokus",
            "rules": [
              {
                "head": 3,
                "label": "geografie",
                "source": "3",
                "target": "1",
                "strength": 1.5,
                "explanation": "Fokussiert die geografische Identit√§t. Die Entit√§t 'Deutschland' sucht nach ihrer funktionalen Entsprechung 'Hauptstadt'."
              },
              {
                "head": 4,
                "label": "geschichte",
                "source": "0",
                "target": "3",
                "strength": 1.5,
                "explanation": "Aktiviert den Archiv-Modus. Der Artikel 'Die' blickt zur√ºck auf die Geschichte der deutschen Entit√§t."
              },
              {
                "head": 2,
                "label": "emotion",
                "source": "1",
                "target": "4",
                "strength": 1.5,
                "explanation": "Verschiebt den Fokus auf die √§sthetische Bewertung des Konzepts 'Hauptstadt' durch das Kopula-Verb."
              },
              {
                "head": 1,
                "label": "sensorik",
                "source": "4",
                "target": "2",
                "strength": 1.5,
                "explanation": "Sucht nach unmittelbaren Umgebungseindr√ºcken (L√§rm, Licht) im Kontext der r√§umlichen Verbindung."
              },
              {
                "head": 1,
                "label": "distanz",
                "source": "2",
                "target": "3",
                "strength": 1.5,
                "explanation": "Berechnet die r√§umliche Entfernung zwischen dem Sprecherstandpunkt und der Entit√§t Deutschland."
              }
            ]
          }
        ]
      },
      "phase_3_ffn": {
        "activations": [
          {
            "id": "geografie",
            "label": "Fakten-Speicher",
            "linked_head": 3,
            "color": "#10b981",
            "icon": "üìö",
            "explanation": "Diese Wissens-Aktivierung greift auf den aktuellen geopolitischen Datensatz zu. Die Analyse ergibt eine √úbereinstimmung zwischen der Entit√§t Deutschland und dem Status von Berlin als Regierungssitz. Es handelt sich um ein rein faktisches Signal ohne subjektive Wertung."
          },
          {
            "id": "geschichte",
            "label": "Archiv-Wissen",
            "linked_head": 4,
            "color": "#8b5cf6",
            "icon": "‚è≥",
            "explanation": "Hier wird das historische Ged√§chtnis des Modells angesprochen. Der Kontext-Mixer erkennt, dass Deutschland eine geteilte Geschichte hat. Dies verschiebt die Wahrscheinlichkeit in Phase 4 zugunsten von Bonn, da der historische Head die zeitliche Dimension priorisiert."
          },
          {
            "id": "emotion",
            "label": "Affektive Ebene",
            "linked_head": 2,
            "color": "#ec4899",
            "icon": "üíñ",
            "explanation": "Die KI-Analyse wechselt hier von Fakten zu Empfindungen. Durch die Verkn√ºpfung von 'Hauptstadt' und 'ist' werden √§sthetische Pr√§dikate aktiviert. Das Modell greift auf g√§ngige menschliche Bewertungen √ºber die Lebensqualit√§t und Sch√∂nheit von Metropolen zu."
          },
          {
            "id": "sensorik",
            "label": "Umgebung/L√§rm",
            "linked_head": 1,
            "color": "#f59e0b",
            "icon": "üöó",
            "explanation": "Dieses Cluster simuliert sensorisches Feedback. Die neuronale Interpretation konzentriert sich auf die physischen Eigenschaften einer Gro√üstadt: L√§rmbelastung, Verkehrsdichte und urbane Hektik. Es unterdr√ºckt faktisches Wissen zugunsten von Adjektiven der Wahrnehmung."
          },
          {
            "id": "distanz",
            "label": "Geografische Distanz",
            "linked_head": 1,
            "color": "#6366f1",
            "icon": "üìè",
            "explanation": "Berechnung der r√§umlichen Tiefe. Das Modell analysiert die Relation 'von Deutschland' als Indikator f√ºr eine geografische Entfernung zum implizierten Beobachter. Dies aktiviert Begriffe, die die Lage im Raum beschreiben."
          }
        ]
      },
      "phase_4_decoding": {
        "settings": {
          "default_temperature": 0.7,
          "default_noise": 0.0,
          "default_mlp_threshold": 0.5,
          "logit_bias_multiplier": 16
        },
        "top_k_tokens": [
          {
            "token": "Berlin",
            "base_logit": 5.2,
            "category_link": "geografie"
          },
          {
            "token": "Bonn",
            "base_logit": 5.0,
            "category_link": "geschichte"
          },
          {
            "token": "sch√∂n",
            "base_logit": 4.8,
            "category_link": "emotion"
          },
          {
            "token": "laut",
            "base_logit": 4.6,
            "category_link": "sensorik"
          },
          {
            "token": "weit weg",
            "base_logit": 4.7,
            "category_link": "distanz"
          }
        ]
      }
    },
    {
      "id": "bankraeuber-polysemie-v01",
      "name": "Die dreifache Bank: Kontext-Analyse",
      "input_prompt": "Der Bankr√§uber sitzt auf einer Bank vor der Bank.",
      "explanation": "Dieses Szenario demonstriert die Aufl√∂sung extremer Polysemie. Drei identische Token 'Bank' werden durch Positional Encoding unterscheidbar gemacht und durch Attention in v√∂llig unterschiedliche semantische Bereiche verschoben.",
      "phase_0_tokenization": {
        "tokens": [
          {
            "id": "0",
            "text": "Der",
            "explanation": "Der bestimmte Artikel im Nominativ Maskulin. Er fungiert hier als Determiner f√ºr das komplexe Subjekt. In der Tokenisierung wird er oft als Startpunkt f√ºr die syntaktische Abh√§ngigkeitsanalyse genutzt."
          },
          {
            "id": "1",
            "text": "Bank",
            "explanation": "Die erste Instanz des Polysems 'Bank'. Ohne Kontext ist sie semantisch unterbestimmt. Da sie jedoch direkt mit 'r√§uber' verkn√ºpft wird, findet eine morphologische Attraktion zum Finanzwesen statt."
          },
          {
            "id": "2",
            "text": "r√§uber",
            "explanation": "Das semantisch dominante Token des Subjekts. Es aktiviert im neuronalen Netzwerk sofort Cluster, die mit Kriminalit√§t, Agitator-Rollen und dem Entzug von Werten assoziiert sind."
          },
          {
            "id": "3",
            "text": "sitzt",
            "explanation": "Ein statisches Verb, das eine r√§umliche Relation zwischen dem Agens (R√§uber) und einem Lokativ (auf einer Bank) fordert. Es erzeugt eine Erwartungshaltung f√ºr ein physisches Objekt im Vektorraum."
          },
          {
            "id": "4",
            "text": "auf",
            "explanation": "Eine lokale Pr√§position, die einen Kontakt zu einer Oberfl√§che impliziert. Linguistisch gesehen ist dies der 'Trigger', der das nachfolgende Token 'Bank' in den Bereich des Mobiliars zwingt."
          },
          {
            "id": "5",
            "text": "einer",
            "explanation": "Ein unbestimmter Artikel im Dativ. Er signalisiert dem Modell, dass ein neues, bisher nicht erw√§hntes physisches Objekt in den Kontext eingef√ºhrt wird."
          },
          {
            "id": "6",
            "text": "Bank",
            "explanation": "Die zweite Instanz. Durch die unmittelbare N√§he zur Pr√§position 'auf' wird der Vektor in Phase 2 stark in Richtung der physischen, greifbaren Objekte verschoben."
          },
          {
            "id": "7",
            "text": "vor",
            "explanation": "Eine relationale Pr√§position, die eine r√§umliche N√§he beschreibt. Sie dient hier als Br√ºcke, um die Szenerie von einem punktuellen Objekt (Parkbank) zu einem gr√∂√üeren architektonischen Kontext (Geb√§ude) zu erweitern."
          },
          {
            "id": "8",
            "text": "der",
            "explanation": "Bestimmter Artikel im Dativ. Im Gegensatz zu 'einer' (Token 5) impliziert 'der' hier eine Bekanntheit oder Einzigartigkeit des Objekts im weiteren Kontext der Erz√§hlung."
          },
          {
            "id": "9",
            "text": "Bank",
            "explanation": "Die dritte Instanz. Sie steht am Ende der Kausalkette. Da der R√§uber 'vor' ihr sitzt, wird dieses Token als massives, ortsfestes Geb√§ude interpretiert, das den institutionellen Rahmen der Szene bildet."
          },
          {
            "id": "10",
            "text": ".",
            "explanation": "Satzende-Marker. Er signalisiert dem Decoder, dass die semantische Integration der vorangegangenen Tokens abgeschlossen ist und die Wahrscheinlichkeitsverteilung f√ºr den n√§chsten Satz berechnet werden kann."
          }
        ]
      },
      "phase_1_embedding": {
        "axis_map": {
          "x_axis": {
            "positive": "Abstrakt & Finanziell",
            "negative": "Physisch & Greifbar",
            "description": "Die X-Achse trennt die funktionale Welt des Geldes (Kreditinstitute) von der materiellen Welt der Objekte (M√∂bel)."
          },
          "y_axis": {
            "positive": "Aktion & Dynamik",
            "negative": "Statik & Ort",
            "description": "Die Y-Achse unterscheidet zwischen handelnden Subjekten/Prozessen und festen, unbeweglichen Verortungen im Raum."
          }
        },
        "token_vectors": [
          {
            "token_index": 0,
            "text": "Der",
            "base_vector": [
              -0.5,
              0.0
            ],
            "positional_vector": [
              0.0,
              0.1
            ],
            "explanation": "Grammatischer Wegweiser. Das Positional Encoding markiert die Startposition der Sequenz."
          },
          {
            "token_index": 1,
            "text": "Bank (1)",
            "base_vector": [
              0.8,
              -0.4
            ],
            "positional_vector": [
              0.05,
              0.09
            ],
            "explanation": "Finanz-Kontext. Das Modell platziert dieses Token initial im abstrakten Quadranten."
          },
          {
            "token_index": 2,
            "text": "r√§uber",
            "base_vector": [
              0.3,
              0.9
            ],
            "positional_vector": [
              0.1,
              0.08
            ],
            "explanation": "Akteur-Token. Besetzt den dynamischen Quadranten durch die implizierte Handlungskraft (Y+)."
          },
          {
            "token_index": 3,
            "text": "sitzt",
            "base_vector": [
              -0.2,
              0.6
            ],
            "positional_vector": [
              0.15,
              0.07
            ],
            "explanation": "Zustandsverb. Es sucht im Vektorraum nach einer Unterlage f√ºr die physische Positionierung."
          },
          {
            "token_index": 4,
            "text": "auf",
            "base_vector": [
              -0.7,
              -0.1
            ],
            "positional_vector": [
              0.2,
              0.06
            ],
            "explanation": "R√§umlicher Connector. Zieht nachfolgende Tokens in den Bereich der physischen Interaktion."
          },
          {
            "token_index": 5,
            "text": "einer",
            "base_vector": [
              -0.4,
              0.0
            ],
            "positional_vector": [
              0.25,
              0.05
            ],
            "explanation": "Artikel zur Objekt-Einleitung im physischen Raum."
          },
          {
            "token_index": 6,
            "text": "Bank (2)",
            "base_vector": [
              0.8,
              -0.4
            ],
            "positional_vector": [
              0.3,
              0.04
            ],
            "explanation": "Identische Basis wie [1], aber das PE signalisiert eine r√§umlich getrennte, neue Entit√§t."
          },
          {
            "token_index": 7,
            "text": "vor",
            "base_vector": [
              -0.6,
              -0.2
            ],
            "positional_vector": [
              0.35,
              0.03
            ],
            "explanation": "Relations-Token f√ºr die Umgebung. Es bereitet den Raum f√ºr eine architektonische Einordnung vor."
          },
          {
            "token_index": 8,
            "text": "der",
            "base_vector": [
              -0.5,
              0.0
            ],
            "positional_vector": [
              0.4,
              0.02
            ],
            "explanation": "Bestimmter Artikel, der eine spezifische Referenz im Weltwissen des Modells anspricht."
          },
          {
            "token_index": 9,
            "text": "Bank (3)",
            "base_vector": [
              0.8,
              -0.4
            ],
            "positional_vector": [
              0.45,
              0.01
            ],
            "explanation": "Dritte Instanz. Durch die Satzposition und die Pr√§position 'vor' wird ein massives Objekt erwartet."
          },
          {
            "token_index": 10,
            "text": ".",
            "base_vector": [
              0.0,
              -1.0
            ],
            "positional_vector": [
              0.5,
              0.0
            ],
            "explanation": "Stopp-Signal. Es schlie√üt die semantische Energie des aktuellen Satzes ab."
          }
        ]
      },
      "phase_2_attention": {
        "attention_profiles": [
          {
            "id": "triple-context-resolver",
            "label": "Polysemie-Entwirrung",
            "rules": [
              {
                "head": 1,
                "label": "finance_crime",
                "source": "2",
                "target": "1",
                "strength": 2.0
              },
              {
                "head": 2,
                "label": "outdoor_furniture",
                "source": "4",
                "target": "6",
                "strength": 1.8
              },
              {
                "head": 3,
                "label": "architecture",
                "source": "7",
                "target": "9",
                "strength": 1.5
              }
            ]
          }
        ]
      },
      "phase_3_ffn": {
        "activations": [
          {
            "id": "finance_crime",
            "label": "Finanzdelikt",
            "linked_head": 1,
            "color": "#dc2626",
            "icon": "üí∏",
            "explanation": "Diese Wissens-Kategorie wird aktiviert, wenn das Token 'Bank' semantisch mit einem T√§ter-Token wie 'R√§uber' verschmilzt. Die neuronale Analyse erkennt hier keine Sitzgelegenheit, sondern ein Zielobjekt f√ºr eine kriminelle Handlung innerhalb des Wirtschaftssystems."
          },
          {
            "id": "outdoor_furniture",
            "label": "Parkmobiliar",
            "linked_head": 2,
            "color": "#16a34a",
            "icon": "üå≥",
            "explanation": "Die Kombination aus der Pr√§position 'auf' und dem Verb 'sitzen' triggert dieses Wissens-Cluster. Es repr√§sentiert das Konzept von h√∂lzernen oder metallischen Sitzgelegenheiten im √∂ffentlichen Raum. Die abstrakte Bank-Bedeutung wird hier fast vollst√§ndig unterdr√ºckt."
          },
          {
            "id": "architecture",
            "label": "St√§dtische Architektur",
            "linked_head": 3,
            "color": "#2563eb",
            "icon": "üèõÔ∏è",
            "explanation": "Dieses Cluster reagiert auf r√§umliche Lagebeschreibungen von gro√üen Objekten. Wenn etwas 'vor' einer Bank geschieht, identifiziert das MLP-Layer das Geb√§ude als architektonischen Fixpunkt. Es aktiviert Wissen √ºber Fassaden, Institutionen und Stadtplanung."
          }
        ]
      },
      "phase_4_decoding": {
        "settings": {
          "default_temperature": 0.6,
          "default_noise": 0.0,
          "default_mlp_threshold": 0.5,
          "logit_bias_multiplier": 20
        },
        "top_k_tokens": [
          {
            "token": "und plant die Flucht.",
            "base_logit": 5.9,
            "category_link": "finance_crime"
          },
          {
            "token": "in der Mittagssonne.",
            "base_logit": 5.4,
            "category_link": "outdoor_furniture"
          },
          {
            "token": "am Hauptplatz.",
            "base_logit": 5.1,
            "category_link": "architecture"
          }
        ]
      }
    }
  ]
}