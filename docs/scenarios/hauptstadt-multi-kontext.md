# Szenario-Dokumentation: Hauptstadt: Der Kontext-Mixer

## 1. Ãœbersicht & Didaktik

* **ID:** `hauptstadt-multi-kontext-v02`
* **Prompt:** *"Die Hauptstadt von Deutschland ist..."*

**Lernziel:**
1. **Kontextuelle Polysemie:** Verstehen, wie ein und derselbe Satzanfang durch unterschiedliche Attention-Fokusse (Heads) vÃ¶llig verschiedene semantische Pfade (Fakt vs. Wertung) einschlagen kann.
2. **Zeitliche Dimensionierung:** Lernen, wie das Modell durch spezifische Heads zwischen aktuellem "Weltwissen" (Berlin) und historischem "Archiv-Wissen" (Bonn) unterscheidet.
3. **Logit-Manipulation:** Nachvollziehen, wie die Aktivierung einer abstrakten Kategorie im Feed-Forward-Network (FFN) die Wahrscheinlichkeitsverteilung des nÃ¤chsten Tokens mathematisch determiniert.

## 2. Technische Logik: Die KausalitÃ¤ts-BrÃ¼cke

### Phase 1 (Embedding): Die Vektorraum-Kartierung

Die Tokens werden in einem 2D-Koordinatensystem verortet, um ihre semantische Natur zu definieren:

* **X-Achse (Inhalt vs. Funktion):** Trennt harte Fakten wie "Deutschland" und "Hauptstadt" (rechts, positiv) von funktionalen Syntax-Elementen wie "ist" und "von" (links, negativ).
* **Y-Achse (Autonomie vs. AbhÃ¤ngigkeit):** Unterscheidet zwischen Tokens, die Kontext suchen (z.B. der Artikel "Die", positiv), und solchen, die eine hohe semantische Dichte besitzen (z.B. "Deutschland", negativ).

### Phase 2 (Attention): Der Routing-Mechanismus (Token-Gating)

Hier entscheiden die Attention-Heads, welche Informationen verknÃ¼pft werden. Die Funktion eines Heads ist dabei strikt an das **Source-Token** (den AuslÃ¶ser) gebunden:

* **Head 3 (Geografie) [Trigger: "Deutschland"]:** Verbindet die EntitÃ¤t (Source 3) mit dem Konzept "Hauptstadt" (Target 1), um die aktuelle, faktische Definition abzurufen.
* **Head 4 (Geschichte) [Trigger: "Die"]:** Der Artikel (Source 0) blickt zurÃ¼ck auf "Deutschland" (Target 3) und aktiviert dadurch den historischen Archiv-Modus (Zeitachse).
* **Head 2 (Emotion) [Trigger: "Hauptstadt"]:** Das Nomen (Source 1) sucht nach einer qualitativen Bewertung im Kopula-Verb "ist" (Target 4).
* **Head 1 (Polysemie & Kontext):** Dieser Head Ã¤ndert seine Funktion je nach Trigger-Wort:
* **Trigger "ist" (Source 4) â†’ Sensorik:** Er sucht nach physischen UmgebungseindrÃ¼cken (LÃ¤rm/Hektik) in Relation zur PrÃ¤position (Target 2).
* **Trigger "von" (Source 2) â†’ Distanz:** Er interpretiert die PrÃ¤position als rÃ¤umlichen Vektor zur EntitÃ¤t "Deutschland" (Target 3) und berechnet die Entfernung.



### Phase 3 (FFN): Die Kategorie-Aktivierung

Basierend auf dem stÃ¤rksten Signal aus Phase 2 feuert das neuronale Netzwerk:

* Dominiert **Head 3**, aktiviert sich der **Fakten-Speicher** (Geografie).
* Dominiert **Head 4**, aktiviert sich das **Archiv-Wissen** (Geschichte).
* Dominiert **Head 2**, aktiviert sich die **Affektive Ebene** (Emotion).

### Phase 4 (Decoding): Der Logit-Shift

Die physische Wahrscheinlichkeit des nÃ¤chsten Wortes wird durch den Bias berechnet. In diesem Szenario gilt der Multiplikator 16:

*  ist die Live-Aktivierung der Kategorie aus Phase 3 (0.0 bis 1.0).
* Ist eine Kategorie voll aktiv (), erhÃ¤lt das zugehÃ¶rige Token (z.B. "Berlin") einen massiven Bonus von  auf den Logit.
* Ist sie inaktiv (), erhÃ¤lt das Token einen Malus von .

## 3. Szenario-JSON (`scenarios.json`)

```json
{
  "id": "hauptstadt-multi-kontext-v02",
  "name": "Hauptstadt: Der Kontext-Mixer",
  "input_prompt": "Die Hauptstadt von Deutschland ist...",
  "explanation": "Dieses Szenario demonstriert, wie ein Transformer-Modell zwischen faktischem Wissen, historischem Archiv-Wissen und subjektiven Bewertungen (Emotion/Sensorik) wechselt, je nachdem, welcher Attention-Pfad durch den Nutzer oder den Kontext verstÃ¤rkt wird.",
  "phase_0_tokenization": {
    "tokens": [
      {
        "id": "0",
        "text": "Die",
        "explanation": "Bestimmter Artikel, Feminin. In diesem Kontext fungiert er als struktureller Anker. Linguistisch leitet er das Subjekt ein und dient im Modell oft als TrÃ¤ger fÃ¼r den Ã¼bergeordneten Satz-Modus (z.B. historisch vs. aktuell)."
      },
      {
        "id": "1",
        "text": "Hauptstadt",
        "explanation": "Ein relationales Nomen, das zwingend eine ErgÃ¤nzung (von X) erfordert. Es aktiviert im FFN-Layer komplexe Wissensstrukturen Ã¼ber Geografie, Verwaltung und nationale IdentitÃ¤t."
      },
      {
        "id": "2",
        "text": "von",
        "explanation": "PrÃ¤position zur Einleitung des Genitiv-Attributs. Sie stellt die logische Verbindung zwischen dem Konzept 'Hauptstadt' und der spezifischen EntitÃ¤t 'Deutschland' her."
      },
      {
        "id": "3",
        "text": "Deutschland",
        "explanation": "Eigennamen-EntitÃ¤t. Dies ist der primÃ¤re Fakten-Anker im Vektorraum. Er liefert die notwendigen Koordinaten, um aus der allgemeinen Kategorie 'Hauptstadt' einen spezifischen geografischen Punkt zu extrahieren."
      },
      {
        "id": "4",
        "text": "ist",
        "explanation": "Kopula-Verb (Sein). Es dient als PrÃ¤dikat und stellt die Ã„quivalenz zwischen dem Subjekt und dem kommenden PrÃ¤dikatsnomen her. Im Decoding-Prozess ist dies der Moment der hÃ¶chsten Entropie vor der Entscheidung."
      }
    ]
  },
  "phase_1_embedding": {
    "axis_map": {
      "x_axis": {
        "positive": "Fakten & EntitÃ¤ten",
        "negative": "Syntax & Funktion",
        "description": "Die X-Achse trennt inhaltliche Ankerpunkte (Berlin, Deutschland) von rein funktionalen Sprachelementen (ist, von)."
      },
      "y_axis": {
        "positive": "Kontext-AbhÃ¤ngigkeit",
        "negative": "Semantische Dichte",
        "description": "Die Y-Achse zeigt, ob ein Token aktiv nach Informationen in der Umgebung sucht oder selbst eine abgeschlossene Bedeutung trÃ¤gt."
      }
    },
    "token_vectors": [
      {
        "token_index": 0,
        "text": "Die",
        "base_vector": [
          -0.9,
          0.8
        ],
        "positional_vector": [
          -0.1,
          0.1
        ],
        "explanation": "Struktureller Artikel: Dient hier als primÃ¤re Quelle fÃ¼r den historischen Pfad (Head 4), um ZustÃ¤nde wie 'ehemalig' zu adressieren."
      },
      {
        "token_index": 1,
        "text": "Hauptstadt",
        "base_vector": [
          0.2,
          0.6
        ],
        "positional_vector": [
          0.1,
          -0.1
        ],
        "explanation": "Relationales Nomen: Besetzt eine zentrale Position im Vektorraum und wartet auf die Spezifizierung durch die 'Deutschland'-EntitÃ¤t."
      },
      {
        "token_index": 2,
        "text": "von",
        "base_vector": [
          -0.7,
          0.9
        ],
        "positional_vector": [
          -0.2,
          0.2
        ],
        "explanation": "Connector: Erzeugt ein starkes Signal fÃ¼r geografische Relationen und Distanzberechnungen (Head 1)."
      },
      {
        "token_index": 3,
        "text": "Deutschland",
        "base_vector": [
          0.95,
          -0.8
        ],
        "positional_vector": [
          0.3,
          -0.2
        ],
        "explanation": "Massive EntitÃ¤t: Liefert die hÃ¶chste semantische Dichte und fungiert als Zielpunkt fÃ¼r fast alle Attention-Heads."
      },
      {
        "token_index": 4,
        "text": "ist",
        "base_vector": [
          -0.85,
          0.7
        ],
        "positional_vector": [
          -0.15,
          0.3
        ],
        "explanation": "Verb-Knoten: Erzeugt die Spannung fÃ¼r das nachfolgende Token und steuert via Head 1 sensorische Assoziationen (laut/schÃ¶n)."
      }
    ]
  },
  "phase_2_attention": {
    "attention_profiles": [
      {
        "id": "mindset-selector",
        "label": "KI-Aufmerksamkeits-Fokus",
        "rules": [
          {
            "head": 3,
            "label": "geografie",
            "source": "3",
            "target": "1",
            "strength": 1.5,
            "explanation": "Fokussiert die geografische IdentitÃ¤t. Die EntitÃ¤t 'Deutschland' sucht nach ihrer funktionalen Entsprechung 'Hauptstadt'."
          },
          {
            "head": 4,
            "label": "geschichte",
            "source": "0",
            "target": "3",
            "strength": 1.5,
            "explanation": "Aktiviert den Archiv-Modus. Der Artikel 'Die' blickt zurÃ¼ck auf die Geschichte der deutschen EntitÃ¤t."
          },
          {
            "head": 2,
            "label": "emotion",
            "source": "1",
            "target": "4",
            "strength": 1.5,
            "explanation": "Verschiebt den Fokus auf die Ã¤sthetische Bewertung des Konzepts 'Hauptstadt' durch das Kopula-Verb."
          },
          {
            "head": 1,
            "label": "sensorik",
            "source": "4",
            "target": "2",
            "strength": 1.5,
            "explanation": "Sucht nach unmittelbaren UmgebungseindrÃ¼cken (LÃ¤rm, Licht) im Kontext der rÃ¤umlichen Verbindung."
          },
          {
            "head": 1,
            "label": "distanz",
            "source": "2",
            "target": "3",
            "strength": 1.5,
            "explanation": "Berechnet die rÃ¤umliche Entfernung zwischen dem Sprecherstandpunkt und der EntitÃ¤t Deutschland."
          }
        ]
      }
    ]
  },
  "phase_3_ffn": {
    "activations": [
      {
        "id": "geografie",
        "label": "Fakten-Speicher",
        "linked_head": 3,
        "color": "#10b981",
        "icon": "ğŸ“š",
        "explanation": "Diese Wissens-Aktivierung greift auf den aktuellen geopolitischen Datensatz zu. Die Analyse ergibt eine Ãœbereinstimmung zwischen der EntitÃ¤t Deutschland und dem Status von Berlin als Regierungssitz. Es handelt sich um ein rein faktisches Signal ohne subjektive Wertung."
      },
      {
        "id": "geschichte",
        "label": "Archiv-Wissen",
        "linked_head": 4,
        "color": "#8b5cf6",
        "icon": "â³",
        "explanation": "Hier wird das historische GedÃ¤chtnis des Modells angesprochen. Der Kontext-Mixer erkennt, dass Deutschland eine geteilte Geschichte hat. Dies verschiebt die Wahrscheinlichkeit in Phase 4 zugunsten von Bonn, da der historische Head die zeitliche Dimension priorisiert."
      },
      {
        "id": "emotion",
        "label": "Affektive Ebene",
        "linked_head": 2,
        "color": "#ec4899",
        "icon": "ğŸ’–",
        "explanation": "Die KI-Analyse wechselt hier von Fakten zu Empfindungen. Durch die VerknÃ¼pfung von 'Hauptstadt' und 'ist' werden Ã¤sthetische PrÃ¤dikate aktiviert. Das Modell greift auf gÃ¤ngige menschliche Bewertungen Ã¼ber die LebensqualitÃ¤t und SchÃ¶nheit von Metropolen zu."
      },
      {
        "id": "sensorik",
        "label": "Umgebung/LÃ¤rm",
        "linked_head": 1,
        "color": "#f59e0b",
        "icon": "ğŸš—",
        "explanation": "Dieses Cluster simuliert sensorisches Feedback. Die neuronale Interpretation konzentriert sich auf die physischen Eigenschaften einer GroÃŸstadt: LÃ¤rmbelastung, Verkehrsdichte und urbane Hektik. Es unterdrÃ¼ckt faktisches Wissen zugunsten von Adjektiven der Wahrnehmung."
      },
      {
        "id": "distanz",
        "label": "Geografische Distanz",
        "linked_head": 1,
        "color": "#6366f1",
        "icon": "ğŸ“",
        "explanation": "Berechnung der rÃ¤umlichen Tiefe. Das Modell analysiert die Relation 'von Deutschland' als Indikator fÃ¼r eine geografische Entfernung zum implizierten Beobachter. Dies aktiviert Begriffe, die die Lage im Raum beschreiben."
      }
    ]
  },
  "phase_4_decoding": {
    "settings": {
      "default_temperature": 0.7,
      "default_noise": 0.0,
      "default_mlp_threshold": 0.5,
      "logit_bias_multiplier": 16
    },
    "top_k_tokens": [
      {
        "token": "Berlin",
        "base_logit": 5.2,
        "category_link": "geografie"
      },
      {
        "token": "Bonn",
        "base_logit": 5.0,
        "category_link": "geschichte"
      },
      {
        "token": "schÃ¶n",
        "base_logit": 4.8,
        "category_link": "emotion"
      },
      {
        "token": "laut",
        "base_logit": 4.6,
        "category_link": "sensorik"
      },
      {
        "token": "weit weg",
        "base_logit": 4.7,
        "category_link": "distanz"
      }
    ]
  }
}

```

## 4. Testplan: Szenarien & Experimente

### Testfall 1: Das Resultat "Berlin" (Der Fakten-Check)

* **Ziel:** Die KI soll logisch/geografisch antworten.
* **Mechanik:** Aktivierung der Kategorie geografie Ã¼ber Head 3.
* **Trigger-Token:** "Deutschland" (ID: 3)

**Aktion:**
1. Fokussiere/Klicke auf das Token "Deutschland".
2. Setze Head 3 auf Maximum (1.0).
3. Setze alle anderen Heads auf diesem Token auf Minimum (0.0).


* **Erwartetes Verhalten:**
* Phase 3: Kategorie "Fakten-Speicher" wird grÃ¼n (Aktivierung > 0.5).
* Phase 4: "Berlin" gewinnt (da Base-Logit 5.2 + massiver Boost).



### Testfall 2: Das Resultat "Bonn" (Der Historiker)

* **Ziel:** Die KI soll in die Vergangenheit blicken (Bonner Republik).
* **Mechanik:** Aktivierung der Kategorie geschichte Ã¼ber Head 4.
* **Trigger-Token:** "Die" (ID: 0)

**Aktion:**
1. Fokussiere/Klicke auf das Token "Die".
2. Setze Head 4 auf Maximum (1.0).
3. **Wichtig:** Stelle sicher, dass Head 3 bei "Deutschland" (aus Test 1) wieder neutral oder niedrig ist, sonst gewinnt Berlin wegen des hÃ¶heren Base-Logits.


**Erwartetes Verhalten:**
* Phase 3: Kategorie "Archiv-Wissen" wird grÃ¼n.
* Phase 4: "Bonn" Ã¼berholt Berlin.



### Testfall 3: Das Resultat "schÃ¶n" (Der Ã„sthet)

* **Ziel:** Die KI soll das Wort "Hauptstadt" emotional bewerten.
* **Mechanik:** Aktivierung der Kategorie emotion Ã¼ber Head 2.
* **Trigger-Token:** "Hauptstadt" (ID: 1)

**Aktion:**
1. Fokussiere/Klicke auf das Token "Hauptstadt".
2. Setze Head 2 auf Maximum (1.0).


**Erwartetes Verhalten:**
* Phase 3: Kategorie "Affektive Ebene" wird grÃ¼n.
* Phase 4: Das Adjektiv "schÃ¶n" gewinnt.



### Testfall 4: Das Resultat "laut" (Der Sensoriker)

* **Ziel:** Die KI soll auf das "ist" (Zustand/Gegenwart) reagieren und LÃ¤rm assoziieren. (Dies ist der erste Test fÃ¼r Head 1).
* **Mechanik:** Aktivierung der Kategorie sensorik Ã¼ber Head 1.
* **Trigger-Token:** "ist" (ID: 4)

**Aktion:**
1. Fokussiere/Klicke auf das Token "ist".
2. Setze Head 1 auf Maximum (1.0).

**Erwartetes Verhalten:**
* Phase 3: Kategorie "Umgebung/LÃ¤rm" wird grÃ¼n.
* Phase 4: "laut" gewinnt.
* **Check:** Die Kategorie "Geografische Distanz" (auch Head 1) darf nicht angehen, da wir auf Token "ist" sind, nicht auf "von".



### Testfall 5: Das Resultat "weit weg" (Der Distanz-Messer)

* **Ziel:** Die KI soll die PrÃ¤position "von" als rÃ¤umliche Trennung interpretieren. (Dies ist der zweite Test fÃ¼r Head 1).
* **Mechanik:** Aktivierung der Kategorie distanz Ã¼ber Head 1.
* **Trigger-Token:** "von" (ID: 2)

**Aktion:**
1. Fokussiere/Klicke auf das Token "von".
2. Setze Head 1 auf Maximum (1.0).
3. Stelle sicher, dass Head 1 beim Token "ist" (aus Test 4) wieder auf 0.0 oder 0.7 steht.

**Erwartetes Verhalten:**
* Phase 3: Kategorie "Geografische Distanz" wird grÃ¼n.
* Phase 4: "weit weg" gewinnt.



## 5. UI/UX & Besonderheiten

* **Visuelles Feedback (Phase 3):**
* ğŸ“š **GrÃ¼n (#10b981):** Fakten/Geografie
* â³ **Violett (#8b5cf6):** Geschichte/Zeit
* ğŸ’– **Pink (#ec4899):** Emotion/Wertung
* ğŸš— **Orange (#f59e0b):** Sensorik/LÃ¤rm
* ğŸ“ **Indigo (#6366f1):** Distanz


* **Besonderheiten der Achsen (Phase 1):**
* Die **X-Achse** dient hier primÃ¤r der Trennung von *Weltwissen* (Berlin, Deutschland) und *Grammatik* (ist, von).
* Die Tokens "Die" und "Deutschland" liegen auf der **Y-Achse** weit auseinander (-0.9 vs +0.95 auf X, aber auch strukturell getrennt), was die unterschiedlichen Zugriffspfade (Head 4 vs Head 3) im Vektorraum plausibilisiert.


* **Logit-Bias-Faktor:**
* In diesem Szenario ist der Multiplikator auf **16** eingestellt (hÃ¶her als der Standard von 12). Dies sorgt fÃ¼r extrem scharfe Entscheidungen ("Winner-takes-all"), sobald ein Head eine Schwelle Ã¼berschreitet.
